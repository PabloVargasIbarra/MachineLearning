{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo clasificatorio sobre enfermos de cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo los datos de kaggle \"Breast Cancer Wisconsin\";<p> https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/data <p>\n",
    "Información sobre los datos en : <p>\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names<p> <p>\n",
    "Tomo como $y=1$ la diagnosis de un tumor maligno, $y=0$ la diagnosis de tumor benigno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv').ix[:, 1:32]\n",
    "data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero divido la muestra en entrenamiento, validación y test con proporcion (60/20/20) <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(data.sample(frac=1, random_state=42),\n",
    "                                 [int(.6*len(data)), int(.8*len(data))])\n",
    "X_train = np.array(train.ix[:,2:32])\n",
    "y_train = np.array(train['diagnosis'])\n",
    "X_validate = np.array(validate.ix[:,2:32])\n",
    "y_validate = np.array(validate['diagnosis'])\n",
    "X_test = np.array(test.ix[:,2:32])\n",
    "y_test = np.array(test['diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo distintos modelos variando el parámetro de regularización C. <p>\n",
    "Calculo para la Accuracy para mis tres particiones en los datos.<p>\n",
    "Calculo la sensibilidad, precisión y especificidad de cada modelo con el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "\n",
    "list_C = np.arange(100 , 1000, 1)\n",
    "score_train = np.zeros(len(list_C)); score_val = np.zeros(len(list_C))\n",
    "score_test = np.zeros(len(list_C)) ; recall_test = np.zeros(len(list_C))\n",
    "precision_test= np.zeros(len(list_C)); count = 0\n",
    "\n",
    "for C in list_C:\n",
    "    reg = linear_model.LogisticRegression(C=C)\n",
    "    reg.fit(X_train, y_train)\n",
    "    score_train[count]= metrics.accuracy_score(\n",
    "        y_train, reg.predict(X_train))\n",
    "    score_val[count] = metrics.accuracy_score(\n",
    "        y_validate, reg.predict(X_validate))\n",
    "    score_test[count] = metrics.accuracy_score(\n",
    "        y_test, reg.predict(X_test))\n",
    "    recall_test[count] = metrics.recall_score(\n",
    "        y_test, reg.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(\n",
    "        y_test, reg.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un data frame para cada modelo de regresión logística utilizado. <p>\n",
    "Cada modelo tiene distinto parámetro C, muestro la accuracy en cada data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  Train Accuracy  Validation Accuracy  Test Accuracy\n",
       "0  100.0        0.973607             0.964912       0.929825\n",
       "1  101.0        0.976540             0.973684       0.921053\n",
       "2  102.0        0.976540             0.964912       0.929825\n",
       "3  103.0        0.982405             0.973684       0.929825\n",
       "4  104.0        0.973607             0.964912       0.929825"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.matrix(np.c_[list_C, score_train, score_val, \n",
    "                         score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['C', 'Train Accuracy', 'Validation Accuracy', \n",
    "              'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.ix[:, :4].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijo el mejor modelo en función de la Accuracy en el validate test. Observo el resto de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C                      284.000000\n",
       "Train Accuracy           0.985337\n",
       "Validation Accuracy      0.982456\n",
       "Test Accuracy            0.929825\n",
       "Test Recall              0.893617\n",
       "Test Precision           0.933333\n",
       "Name: 184, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index = models['Validation Accuracy'].idxmax()\n",
    "models.ix[best_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo lo hemos elegido tomando como parámetro el validate set. <p>\n",
    "La manera correcta de estimar la capacidad de generalización es evaluarla sobre el test set. <p>\n",
    "Si lo hicieramos sobre el validate test, sobreestimariamos su capacidad al haberlo tomado como parámetro al elegir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=284, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LogisticRegression(C=list_C[best_index])\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión evaluada en el **train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          216            2\n",
       "Actual 1            3          120"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_train = metrics.confusion_matrix(y_train,\n",
    "                         reg.predict(X_train))\n",
    "pd.DataFrame(data = m_confusion_train, \n",
    "            columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión evaluada en el **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0           71            1\n",
       "Actual 1            1           41"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_validate = metrics.confusion_matrix(y_validate,\n",
    "                         reg.predict(X_validate))\n",
    "pd.DataFrame(data = m_confusion_validate, \n",
    "            columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión evaluada en el **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0           64            3\n",
       "Actual 1            5           42"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test,\n",
    "                         reg.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, \n",
    "             columns = ['Predicted 0', 'Predicted 1'],\n",
    "             index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo sobre mi modelo que el error de generalización está sobre estimado si lo evaluo sobre el conjunto de validación\n",
    "#### Esto es debido a que la elección del parámetro de regularización está sujeta a él.\n",
    "#### Mi precisión al generalizar es aproximadamente un 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, reg.predict_proba(X_test)[:, 1], pos_label = 1, drop_intermediate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         1.00000000e+00,   9.99999992e-01,   9.99999987e-01,\n",
       "         9.99999982e-01,   9.99999977e-01,   9.99999962e-01,\n",
       "         9.99999634e-01,   9.99999430e-01,   9.99997347e-01,\n",
       "         9.99995450e-01,   9.99989313e-01,   9.99976153e-01,\n",
       "         9.99966246e-01,   9.99880366e-01,   9.99873101e-01,\n",
       "         9.99799594e-01,   9.99752824e-01,   9.99521204e-01,\n",
       "         9.99339706e-01,   9.98997848e-01,   9.95343371e-01,\n",
       "         9.92472845e-01,   9.92150231e-01,   9.88342522e-01,\n",
       "         9.86417009e-01,   9.79136747e-01,   9.74509028e-01,\n",
       "         9.72923324e-01,   9.37638186e-01,   7.22175295e-01,\n",
       "         6.37456152e-01,   5.89233012e-01,   5.39295844e-01,\n",
       "         5.36166641e-01,   4.02919311e-01,   3.01092050e-01,\n",
       "         2.31398099e-01,   2.25327197e-01,   1.78117882e-01,\n",
       "         9.66192778e-02,   7.19959429e-02,   7.11053607e-02,\n",
       "         5.51085239e-02,   3.70330323e-02,   3.11592758e-02,\n",
       "         3.02359427e-02,   2.09443467e-02,   1.93582372e-02,\n",
       "         1.72664292e-02,   1.00193288e-02,   9.76909317e-03,\n",
       "         9.49831241e-03,   8.25133173e-03,   7.55145541e-03,\n",
       "         5.33761391e-03,   5.30747176e-03,   2.87280532e-03,\n",
       "         2.81125399e-03,   2.81075486e-03,   2.06401399e-03,\n",
       "         2.00008207e-03,   1.99645223e-03,   1.49313530e-03,\n",
       "         1.36908132e-03,   9.88831951e-04,   9.14633397e-04,\n",
       "         8.33779949e-04,   8.25952628e-04,   7.60545106e-04,\n",
       "         7.48727407e-04,   7.45588192e-04,   7.23196144e-04,\n",
       "         6.95420115e-04,   5.84333389e-04,   5.40027026e-04,\n",
       "         5.33314087e-04,   5.03826095e-04,   4.91303985e-04,\n",
       "         4.61211405e-04,   3.31581420e-04,   2.98431383e-04,\n",
       "         2.75588040e-04,   2.67040342e-04,   2.54169305e-04,\n",
       "         2.11734671e-04,   1.32085820e-04,   8.74500826e-05,\n",
       "         7.85577585e-05,   6.45041844e-05,   5.62875616e-05,\n",
       "         5.40185819e-05,   4.81957398e-05,   4.26350432e-05,\n",
       "         4.25143689e-05,   2.60678331e-05,   2.03491334e-05,\n",
       "         1.46711406e-05,   1.23402860e-05,   1.06921730e-05,\n",
       "         1.03941175e-05,   7.44125559e-06,   5.91377770e-06,\n",
       "         4.06675621e-06])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
