{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de enfermos con cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo los datos de kaggle \"Breast Cancer Wisconsin\";<p> https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/data <p>\n",
    "Información sobre los datos en : <p>\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names<p> <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomo como $y=1$ la diagnosis de un tumor maligno, $y=0$ la diagnosis de tumor benigno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cancer.csv').ix[:, 1:32]\n",
    "data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero divido la muestra en entrenamiento, validación y test con proporcion (60/20/20) <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(data.sample(frac=1, random_state=42),\n",
    "                                 [int(.6*len(data)), int(.8*len(data))])\n",
    "X_train = np.array(train.ix[:,2:32])\n",
    "y_train = np.array(train['diagnosis'])\n",
    "X_validate = np.array(validate.ix[:,2:32])\n",
    "y_validate = np.array(validate['diagnosis'])\n",
    "X_test = np.array(test.ix[:,2:32])\n",
    "y_test = np.array(test['diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo distintos modelos variando el parámetro de regularización C. <p>\n",
    "Calculo para la Accuracy para mis tres particiones en los datos.<p>\n",
    "Calculo la sensibilidad, precisión y especificidad de cada modelo con el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_C = np.arange(100 , 1000, 1)\n",
    "score_train = np.zeros(len(list_C)); score_val = np.zeros(len(list_C))\n",
    "score_test = np.zeros(len(list_C)) ; recall_test = np.zeros(len(list_C))\n",
    "precision_test= np.zeros(len(list_C)); count = 0\n",
    "\n",
    "for C in list_C:\n",
    "    reg = linear_model.LogisticRegression(C=C)\n",
    "    reg.fit(X_train, y_train)\n",
    "    score_train[count]= metrics.accuracy_score(\n",
    "        y_train, reg.predict(X_train))\n",
    "    score_val[count] = metrics.accuracy_score(\n",
    "        y_validate, reg.predict(X_validate))\n",
    "    score_test[count] = metrics.accuracy_score(\n",
    "        y_test, reg.predict(X_test))\n",
    "    recall_test[count] = metrics.recall_score(\n",
    "        y_test, reg.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(\n",
    "        y_test, reg.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un data frame para cada modelo de regresión logística utilizado. <p>\n",
    "Cada modelo tiene distinto parámetro C, muestro la accuracy en cada data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = np.matrix(np.c_[list_C, score_train, score_val, \n",
    "                         score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['C', 'Train Accuracy', 'Validation Accuracy', \n",
    "              'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.ix[:, :4].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijo el mejor modelo en función de la Accuracy en el validate test. Observo el resto de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_index = models['Validation Accuracy'].idxmax()\n",
    "models.ix[best_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo lo hemos elegido tomando como parámetro el validate set. <p>\n",
    "La manera correcta de estimar la capacidad de generalización es evaluarla sobre el test set. <p>\n",
    "Si lo hicieramos sobre el validate test, sobreestimariamos su capacidad al haberlo tomado como parámetro al elegir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LogisticRegression(C=list_C[best_index])\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión evaluada en el **train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_confusion_train = metrics.confusion_matrix(y_train,\n",
    "                         reg.predict(X_train))\n",
    "pd.DataFrame(data = m_confusion_train, \n",
    "            columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión evaluada en el **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_confusion_validate = metrics.confusion_matrix(y_validate,\n",
    "                         reg.predict(X_validate))\n",
    "pd.DataFrame(data = m_confusion_validate, \n",
    "            columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión evaluada en el **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test,\n",
    "                         reg.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, \n",
    "             columns = ['Predicted 0', 'Predicted 1'],\n",
    "             index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observo sobre mi modelo que el error de generalización está sobre estimado si lo evaluo sobre el conjunto de validación\n",
    "#### Esto es debido a que la elección del parámetro de regularización está sujeta a él.\n",
    "#### Mi precisión al generalizar es aproximadamente un 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_1 = reg.predict_proba(X_validate)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_validate,prob_1, \n",
    "                                 pos_label = 1)\n",
    "print('Límites de decisión óptimos :  ' +  str(thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=1, label='AUC = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlim([-0.1, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Especificidad')\n",
    "plt.ylabel('Sensibilidad')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
